{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, import_ipynb, ipynb\n",
    "if os.getcwd() == 'C:\\\\Users\\\\admin\\\\Desktop\\\\retail_data_analysis\\\\code':\n",
    "    print (\"Already in code directory\")\n",
    "else:\n",
    "    os.chdir('..//code')\n",
    "        \n",
    "# import python libraries\n",
    "from importLibraries import *\n",
    "\n",
    "\n",
    "def fun_lda():   \n",
    "    \n",
    "    os.chdir('..//input')\n",
    "    input_data_preProcessed = pd.read_csv(\"input_data_preProcessed.csv\")\n",
    "    input_data_preProcessed_Description = input_data_preProcessed[['Description']]\n",
    "    \n",
    "    \n",
    "    input_data_preProcessed_Description['Description'] = input_data_preProcessed_Description['Description'].apply(lambda x: \"\".join(x) )\n",
    "    input_data_preProcessed_Description = input_data_preProcessed_Description['Description'].tolist()\n",
    "    \n",
    "    # LDA can only use raw term counts (not tfidf) because its a PGM\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.9, min_df=25, analyzer='word', ngram_range=(1, 2), max_features=1000, stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(input_data_preProcessed_Description)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "\n",
    "    # Run LDA\n",
    "    lda = LatentDirichletAllocation(n_components = 4, max_iter=2, learning_method='online', learning_offset=50.).fit(tf)\n",
    "    \n",
    "    \n",
    "    def display_topics(model, feature_names, no_top_words):\n",
    "        topic_dict = {}\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i]) for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "            topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i]) for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        return pd.DataFrame(topic_dict)\n",
    "\n",
    "    no_top_words = 5\n",
    "    lda_result = display_topics(lda, tf_feature_names, no_top_words)\n",
    "    display(lda_result)\n",
    "    display(\"Perplexity of this model is: \", lda.perplexity(tf))\n",
    "    \n",
    "    # Optimal number of topics using grid search\n",
    "    # One way to find the optimal number of topics is to train with different values of alpha and beta and test perplexity on test data and whichever alpha, beta gives minimum perplexity on test data choose that value of alpha and beta\n",
    "# To determine the best model, GridSearchCV uses the approximate log-likelihood as score (not perplexity). \n",
    "    # One way to find the optimal number of topics is to train with different values of alpha and beta and test perplexity on test data and whichever alpha, beta gives minimum perplexity on test data choose that value of alpha and beta\n",
    "    search_params = {'n_components': [4, 5, 6], 'learning_decay': [.5, .7]}\n",
    "    # Init the Model\n",
    "    lda = LatentDirichletAllocation(max_iter=2, learning_method='online', batch_size=128, evaluate_every = -1,  n_jobs = -1)\n",
    "    # Init Grid Search Class\n",
    "    model = GridSearchCV(lda, param_grid=search_params)\n",
    "    # Do the Grid Search\n",
    "    model.fit(tf)\n",
    "    # Best Model\n",
    "    best_lda_model = model.best_estimator_\n",
    "    # Model Parameters\n",
    "    print(\"Best Model's Params: \", model.best_params_)\n",
    "    # Log Likelihood Score\n",
    "    print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "    # Perplexity\n",
    "    print(\"Model Perplexity: \", best_lda_model.perplexity(tf))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
